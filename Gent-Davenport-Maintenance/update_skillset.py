"""
Update the maintenance-manuals skillset with:
1. Davenport-specific image verbalization prompt (for diagrams, parts lists, schematics)
2. Better embedding model (text-embedding-3-large at 1536d)

The skillset was auto-generated by Foundry with a generic "describe this image" prompt
and text-embedding-3-small. This script switches to text-embedding-3-large truncated to
1536 dimensions — better quality embeddings without changing the index vector fields.
It then resets and re-runs the indexer so all documents get re-processed.

IMPORTANT: Requires AOAI_KEY environment variable.
Azure Search GET returns apiKey fields as "<redacted>" — we must inject the real key
before PUTting the skillset back, or all skills lose their auth and fail with 401.

Get key:
  az cognitiveservices account keys list --name aoai-j6lw7vswhnnhw --resource-group rg-gent-foundry-eus2 --query key1 -o tsv

Usage:
  python update_skillset.py
"""

import os
import time
import requests
from dotenv import load_dotenv
from azure.identity import DefaultAzureCredential

# Load .env file from the script's directory (keeps secrets out of shell history)
load_dotenv(os.path.join(os.path.dirname(__file__), ".env"), override=True)

# Azure resource configuration
SEARCH_ENDPOINT = "https://srch-j6lw7vswhnnhw.search.windows.net"
AOAI_RESOURCE_URL = "https://aoai-j6lw7vswhnnhw.openai.azure.com"
API_VERSION = "2025-11-01-Preview"

# Embedding model - text-embedding-3-large truncated to 1536d
# The auto-generated index has 1536d vector fields, so we keep dimensions=1536.
# Using -large at 1536d gives better quality than -small at 1536d (Matryoshka embeddings).
# IMPORTANT: deploymentId must match the Foundry deployment name exactly (includes suffix)
EMBEDDING_DEPLOYMENT = "text-embedding-3-large-088065"  # Foundry deployment name
EMBEDDING_MODEL_NAME = "text-embedding-3-large"          # actual model name
EMBEDDING_DIMENSIONS = 1536  # truncated from 3072 — fits existing index, better quality

# AOAI API key - required because Azure Search masks keys as "<redacted>" on GET,
# so we must re-inject the real key before writing the skillset back
AOAI_KEY = os.environ.get("AOAI_KEY")

# Chat model for image verbalization
CHAT_DEPLOYMENT = "gpt-5-mini"

# Parallelism for ChatCompletionSkill — process multiple images concurrently.
# Default is 1 (sequential). Higher = faster but more AOAI quota usage.
# 5 is a good balance: cuts image processing time ~5x without hammering the endpoint.
CHAT_SKILL_PARALLELISM = 5

# Skill timeout — default PT1M is too short for image-heavy docs.
# A single PDF with many images can take 30+ minutes to verbalize.
CHAT_SKILL_TIMEOUT = "PT2H"

# Indexer schedule — auto-resume after the 2-hour execution timeout.
# Azure Search indexers are single-instance, so if one is already running the
# scheduled trigger is simply skipped (no queue, no backlog).
INDEXER_SCHEDULE_INTERVAL = "PT30M"  # ISO 8601: every 30 minutes

# Davenport-specific image verbalization prompt
# This replaces the generic "Please describe this image" with a prompt that
# extracts the technical details machinists actually search for
IMAGE_SYSTEM_PROMPT = (
    "You are a technical documentation specialist for Davenport Model B "
    "5-Spindle Automatic Screw Machines. You extract detailed, searchable "
    "information from engineering diagrams, parts drawings, and schematics."
)

# NOTE: No newlines (\n) allowed - Azure Search OData expressions can't parse
# them inside string literals. Use spaces/punctuation to structure the prompt.
IMAGE_USER_PROMPT = (
    "Analyze this technical image and extract ALL of the following: "
    "1) PART NUMBERS - List every part number visible (e.g., 5080-131, 843, 1263-77). "
    "2) COMPONENT NAMES - Identify what each part number refers to if labeled. "
    "3) SPECIFICATIONS - Note any dimensions, clearances, tolerances "
    "(e.g., .004/.006 clearance). "
    "4) VIEW TYPE - Identify if this is a cross-section, exploded view, "
    "assembly drawing, parts list, etc. "
    "5) ASSEMBLY/SECTION - Name the assembly or section shown "
    "(e.g., Roll Away Clutch, Feed Mechanism, Spindle Assembly). "
    "6) RELATIONSHIPS - Describe how parts connect or interact. "
    "Format as structured text that would help a machinist find this diagram "
    "when searching for specific parts or procedures."
)

# Skillsets to update - starting with maintenance-manuals
SKILLSETS_TO_UPDATE = [
    "ks-azureblob-maintenance-manuals-skillset",
    # Uncomment when ready to fix the other skillsets:
    # "ks-azureblob-engineering-tips-skillset",
    # "ks-azureblob-technical-tips-skillset",
    # "ks-azureblob-troubleshooting-skillset",
    # "ks-azureblob-video-training-skillset",
]


def get_search_headers(credential):
    """Get auth headers for Azure Search REST API."""
    token = credential.get_token("https://search.azure.com/.default")
    return {
        "Authorization": f"Bearer {token.token}",
        "Content-Type": "application/json",
    }


def get_skillset(headers, skillset_name):
    """Fetch the current skillset definition."""
    url = f"{SEARCH_ENDPOINT}/skillsets/{skillset_name}?api-version={API_VERSION}"
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    return response.json()


def update_skillset(headers, skillset):
    """Push the updated skillset definition back to Azure Search."""
    name = skillset["name"]
    url = f"{SEARCH_ENDPOINT}/skillsets/{name}?api-version={API_VERSION}"

    # Must include If-Match header with the etag for updates
    update_headers = {**headers, "If-Match": skillset["@odata.etag"]}

    response = requests.put(url, headers=update_headers, json=skillset)
    response.raise_for_status()
    # PUT may return 200 with body or 204 No Content - both are success
    if response.content:
        return response.json()
    return None


def restore_api_keys(skillset, api_key):
    """Replace masked '<redacted>' apiKey values with the real key.

    Azure Search returns apiKey as '<redacted>' on GET for security.
    If we PUT that back, the skills lose auth and fail with 401.
    """
    restored = 0
    for skill in skillset.get("skills", []):
        if "apiKey" in skill:
            skill["apiKey"] = api_key
            restored += 1
    return restored


def fix_skillset(headers, skillset_name):
    """Update a skillset with better image prompt and correct embedding model."""
    print(f"\n  Fetching skillset '{skillset_name}'...")
    skillset = get_skillset(headers, skillset_name)

    # Restore API keys that came back as "<redacted>" from the GET
    restored = restore_api_keys(skillset, AOAI_KEY)
    print(f"  Restored API keys on {restored} skill(s)")

    changes_made = []

    for skill in skillset.get("skills", []):
        skill_type = skill.get("@odata.type", "")
        skill_name = skill.get("name", "")

        # Fix embedding skills - switch to text-embedding-3-large at 1536d
        if skill_type == "#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill":
            old_model = skill.get("deploymentId", "unknown")
            if old_model != EMBEDDING_DEPLOYMENT:
                skill["deploymentId"] = EMBEDDING_DEPLOYMENT
                skill["modelName"] = EMBEDDING_MODEL_NAME
                skill["dimensions"] = EMBEDDING_DIMENSIONS
                changes_made.append(
                    f"  [FIX] {skill_name}: {old_model} -> {EMBEDDING_DEPLOYMENT} "
                    f"({EMBEDDING_DIMENSIONS} dimensions)"
                )

        # Fix image verbalization — prompt + parallelism
        if skill_type == "#Microsoft.Skills.Custom.ChatCompletionSkill":
            # Set degreeOfParallelism so multiple images process concurrently
            old_parallelism = skill.get("degreeOfParallelism", 1)
            if old_parallelism != CHAT_SKILL_PARALLELISM:
                skill["degreeOfParallelism"] = CHAT_SKILL_PARALLELISM
                changes_made.append(
                    f"  [FIX] {skill_name} parallelism: {old_parallelism} -> {CHAT_SKILL_PARALLELISM}"
                )

            # Set timeout — default PT1M is too short for image-heavy docs
            old_timeout = skill.get("timeout", "PT1M")
            if old_timeout != CHAT_SKILL_TIMEOUT:
                skill["timeout"] = CHAT_SKILL_TIMEOUT
                changes_made.append(
                    f"  [FIX] {skill_name} timeout: {old_timeout} -> {CHAT_SKILL_TIMEOUT}"
                )

            for inp in skill.get("inputs", []):
                if inp["name"] == "systemMessage":
                    old_prompt = inp.get("source", "")
                    inp["source"] = f"='{IMAGE_SYSTEM_PROMPT}'"
                    changes_made.append(
                        f"  [FIX] {skill_name} systemMessage: updated to Davenport-specific"
                    )
                if inp["name"] == "userMessage":
                    old_prompt = inp.get("source", "")
                    inp["source"] = f"='{IMAGE_USER_PROMPT}'"
                    changes_made.append(
                        f"  [FIX] {skill_name} userMessage: updated with part number extraction"
                    )

    if not changes_made:
        print("  No changes needed")
        return False

    # Push the updated skillset
    print("\n  Changes:")
    for change in changes_made:
        print(f"    {change}")

    print(f"\n  Updating skillset...")
    update_skillset(headers, skillset)
    print(f"  [OK] Skillset updated")
    return True


def set_indexer_schedule(headers, skillset_name):
    """Add a recurring schedule to the indexer so it auto-resumes after timeout.

    Azure Search has a 2-hour execution limit per run. For image-heavy pipelines
    that need more time, scheduling lets the indexer pick up where it left off.
    Indexers are single-instance — if already running, the scheduled trigger is skipped.
    """
    indexer_name = skillset_name.replace("-skillset", "-indexer")

    # GET current indexer definition
    url = f"{SEARCH_ENDPOINT}/indexers/{indexer_name}?api-version={API_VERSION}"
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    indexer = response.json()

    # Check if schedule already matches
    current_schedule = indexer.get("schedule", {})
    current_interval = current_schedule.get("interval", None)
    if current_interval == INDEXER_SCHEDULE_INTERVAL:
        print(f"  Schedule already set to {INDEXER_SCHEDULE_INTERVAL} — no change needed")
        return

    # Set the schedule
    indexer["schedule"] = {"interval": INDEXER_SCHEDULE_INTERVAL}

    # PUT updated indexer back (include etag for safe update)
    update_headers = {**headers, "If-Match": indexer["@odata.etag"]}
    response = requests.put(url, headers=update_headers, json=indexer)
    response.raise_for_status()
    print(f"  [OK] Indexer schedule set to {INDEXER_SCHEDULE_INTERVAL} "
          f"(was: {current_interval or 'none'})")


def reset_and_run_indexer(headers, skillset_name):
    """Reset and run the corresponding indexer."""
    # Derive indexer name from skillset name (replace -skillset with -indexer)
    indexer_name = skillset_name.replace("-skillset", "-indexer")

    print(f"\n  Resetting indexer '{indexer_name}'...")
    url = f"{SEARCH_ENDPOINT}/indexers/{indexer_name}/reset?api-version={API_VERSION}"
    response = requests.post(url, headers=headers)
    response.raise_for_status()
    print(f"  [OK] Indexer reset")

    print(f"  Running indexer '{indexer_name}'...")
    url = f"{SEARCH_ENDPOINT}/indexers/{indexer_name}/run?api-version={API_VERSION}"
    response = requests.post(url, headers=headers)
    response.raise_for_status()
    print(f"  [OK] Indexer started")


def main():
    print("=" * 60)
    print("Update Skillsets - Better Image Prompts & Embedding Model")
    print("=" * 60)

    if not AOAI_KEY:
        print("\nERROR: AOAI_KEY environment variable not set")
        print("Get key: az cognitiveservices account keys list --name aoai-j6lw7vswhnnhw "
              "--resource-group rg-gent-foundry-eus2 --query key1 -o tsv")
        print("Then set: $env:AOAI_KEY = 'your-key-here'")
        return

    credential = DefaultAzureCredential()
    headers = get_search_headers(credential)

    for skillset_name in SKILLSETS_TO_UPDATE:
        print(f"\n{'=' * 60}")
        print(f"Processing: {skillset_name}")

        changed = fix_skillset(headers, skillset_name)

        # Always set the schedule (even if skillset didn't change)
        print(f"\n  Setting indexer schedule...")
        set_indexer_schedule(headers, skillset_name)

        if changed:
            reset_and_run_indexer(headers, skillset_name)
        else:
            print("  Skipping indexer reset (no changes)")

    print(f"\n{'=' * 60}")
    print("DONE! Skillset(s) updated and indexer(s) restarted.")
    print("\nThe indexer will re-process all documents with:")
    print(f"  - Embedding model: {EMBEDDING_DEPLOYMENT} ({EMBEDDING_DIMENSIONS}d)")
    print("  - Image prompt: Davenport-specific part number extraction")
    print(f"  - Image parallelism: {CHAT_SKILL_PARALLELISM} concurrent calls")
    print(f"  - Schedule: every {INDEXER_SCHEDULE_INTERVAL} (auto-resume after timeout)")
    print("\nCheck Azure Portal > AI Search > Indexers for progress.")
    print("=" * 60)


if __name__ == "__main__":
    main()
